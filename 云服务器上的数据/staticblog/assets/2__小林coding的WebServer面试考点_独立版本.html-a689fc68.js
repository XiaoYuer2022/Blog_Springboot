import{$ as r,a0 as d,a1 as t,a6 as n,a2 as l,a3 as e,a4 as a,a5 as p,I as o}from"./framework-e783454b.js";const c={},s=l("div",{class:"hint-container tip"},[l("p",{class:"hint-container-title"},"提示"),l("p",null,"WebServer项目相关")],-1),h=l("h1",{id:"小林的面经",tabindex:"-1"},[l("a",{class:"header-anchor",href:"#小林的面经","aria-hidden":"true"},"#"),e(" 小林的面经")],-1),u={href:"https://mp.weixin.qq.com/s/aBD8pgOa02OBjlGrFAvpCA",target:"_blank",rel:"noopener noreferrer"},_=p('<h2 id="_1、存字符串用unordered-map还是用map好-为什么-要怎么优化" tabindex="-1"><a class="header-anchor" href="#_1、存字符串用unordered-map还是用map好-为什么-要怎么优化" aria-hidden="true">#</a> 1、存字符串用<code>unordered_map</code>还是用<code>map</code>好？为什么？要怎么优化？</h2><p>答：   <strong>map和unordered_map的优缺点</strong> map优点：map是有序的、基于红黑树实现，查找的时间复杂度是O(n) map缺点：空间占用率比较高，因为内部实现了红黑树，虽然提高了运行效率，但是每个节点都要保存父亲节点和孩子节点和红黑树的性质，使得每一个节点都占用大量的空间。   <strong>适用的情况</strong>：对于要有序的结构，使用map。 unordered_map优点：因为内部是哈希表来实现的，所以查找效率会非常高。 unordered_map缺点：哈希表的建立比较费时   <strong>适用的情况</strong>：对于查找问题，使用unordered_map会更好一点。</p><p>  （以下内容来源于chatgpt）存储字符串时，unordered_map和map都可以使用，但它们在性能、内存消耗和功能方面有所不同。</p><ol><li>访问效率：</li></ol><ul><li>unordered_map 使用哈希表实现，在大多数情况下，查找元素的时间复杂度为O(1)。因此，当需要快速查找元素时，unordered_map是更好的选择。</li><li>map 使用红黑树实现，查找元素的时间复杂度为O(log n)，其中n是元素的数量。相对于unordered_map，map查找稍慢一些。</li></ul><ol start="2"><li>内存消耗：</li></ol><ul><li>unordered_map 使用哈希表存储数据，因此可能需要更多的内存来存储哈希表本身和哈希冲突时的解决方案。</li><li>map 使用红黑树存储数据，虽然红黑树会占用额外的内存，但通常整体上比unordered_map消耗更少的内存。</li></ul><ol start="3"><li>键的排序：</li></ol><ul><li>unordered_map 不对键进行排序，键的顺序是不确定的。</li><li>map 默认会按照键的升序进行排序，这种特性非常适合需要有序访问元素的情况。   综上所述，如果你更关注快速的查找操作，并且不需要键的排序，可以选择unordered_map。如果你需要有序访问元素，或者希望降低内存消耗，可以选择map。最终的选择还取决于你对性能和功能的具体需求。</li></ul><h2 id="_2、有一个请求队列-有读者线程和写者线程-在同时操作这个共享的请求队列-属于什么样的读写模型" tabindex="-1"><a class="header-anchor" href="#_2、有一个请求队列-有读者线程和写者线程-在同时操作这个共享的请求队列-属于什么样的读写模型" aria-hidden="true">#</a> 2、有一个请求队列,有读者线程和写者线程 在同时操作这个共享的请求队列,属于什么样的读写模型 ？</h2><p>答：属于生产者-消费者模型</p><h2 id="_3、一写多读模型的情况下怎么解决读写冲突的问题-加锁是一种方案-但是会影响性能-有没有更好的办法" tabindex="-1"><a class="header-anchor" href="#_3、一写多读模型的情况下怎么解决读写冲突的问题-加锁是一种方案-但是会影响性能-有没有更好的办法" aria-hidden="true">#</a> 3、一写多读模型的情况下怎么解决读写冲突的问题？加锁是一种方案,但是会影响性能,有没有更好的办法？</h2>',12),m={href:"https://blog.csdn.net/simon_2011/article/details/79014110",target:"_blank",rel:"noopener noreferrer"},b=p('<ul><li>一写多读（含一写一读）</li><li>多写一读</li><li>多写多读</li></ul><h2 id="_4、select和epoll有什么区别" tabindex="-1"><a class="header-anchor" href="#_4、select和epoll有什么区别" aria-hidden="true">#</a> 4、select和epoll有什么区别？</h2><p>答：他们两个，甚至包含poll都是IO多路复用的系统调用，select是一种较老的系统调用，epoll则比较新。</p><ol><li>工作方式：</li></ol><ul><li>select 是阻塞式的，它会一直等待直到指定的文件描述符之一就绪或超时。每次调用select时都需要将所有感兴趣的文件描述符集合传递给它。</li><li>epoll 使用更加高效的事件通知机制，采用&quot;就绪列表&quot;的方式来避免遍历所有文件描述符。它通过在内核中注册事件，只返回就绪的文件描述符，从而提高了性能。</li></ul><ol start="2"><li>可扩展性：</li></ol><ul><li>select 的可扩展性较差，它使用线性扫描方式对所有的文件描述符进行轮询，当文件描述符数量较大时，性能会下降。</li><li>epoll 利用操作系统提供的epoll机制，可以监听大量的文件描述符，并且在文件描述符就绪时立即得到通知，因此它在处理大量并发连接时具有更好的可扩展性。</li></ul><ol start="3"><li>文件描述符管理：</li></ol><ul><li>select 的文件描述符集合大小是固定的，需要通过修改宏定义来改变，默认情况下是1024。这意味着在使用select时，需要事先设置一个足够大的文件描述符集合，并关注其中的文件描述符。</li><li>epoll 不限制文件描述符集合的大小，它只需要关注真正发生事件的文件描述符，可以动态地添加和删除感兴趣的文件描述符。   综上所述，epoll相对于select在性能和可扩展性方面有优势。它通过更高效的事件通知机制和可变大小的文件描述符集合使得并发连接的处理更为高效。因此，在大规模并发服务器开发中，epoll通常是更常用的选择。但对于小规模应用或特定的情况，select也可能是一个简单而有效的选择。</li></ul><h2 id="_5、epoll中可以无限承载socket的连接吗-创建socket时的返回值是什么" tabindex="-1"><a class="header-anchor" href="#_5、epoll中可以无限承载socket的连接吗-创建socket时的返回值是什么" aria-hidden="true">#</a> 5、epoll中可以无限承载socket的连接吗？创建socket时的返回值是什么？</h2><p>答：在epoll中，理论上可以承载无限数量的Socket连接。epoll采用事件驱动的方式，通过注册和监听文件描述符（包括Socket描述符），只返回就绪的文件描述符，并且可以动态地添加和删除感兴趣的文件描述符。这种机制使得epoll具有更好的可扩展性，能够处理大规模并发连接。</p><p>  在创建Socket时，返回值是一个非负整数，表示创建的Socket文件描述符。如果创建失败，返回值通常是-1，并且设置错误码以指示具体错误原因。请注意，Socket描述符是一个整数，可以在后续的网络编程中使用它来进行读写操作、设置选项以及进行其他操作。</p><p>  需要注意的是，尽管epoll本身没有对文件描述符个数的限制，但是操作系统可能对每个进程所能打开的文件描述符数量进行了限制。因此，在实际使用过程中，需要根据系统的最大文件描述符限制和资源消耗进行适当的调优，确保能够处理预期的并发连接数。</p><h2 id="_6、fd在系统中有限制吗-可以无限申请吗" tabindex="-1"><a class="header-anchor" href="#_6、fd在系统中有限制吗-可以无限申请吗" aria-hidden="true">#</a> 6、fd在系统中有限制吗？可以无限申请吗？</h2><p>答：在大多数系统中都对fd做了限制，在Linux下一般文件描述符最多可打开1024个，不过你可以使用ulimit命令或者修改<code>/etc/security/limits.conf</code>系统配置文件来增加或减少进程的最大文件描述符限制。对于不同的操作系统和发行版，最大文件描述符限制可能会有所不同。例如，在Windows系统中，默认的最大文件描述符限制是2048。</p><p>  需要注意的是，尽管可以通过调整最大文件描述符限制来提高进程所能打开的文件描述符数量，但是资源消耗和性能问题也需要考虑。过多地申请文件描述符可能会导致系统资源紧张，从而影响系统的稳定性和性能。</p><h2 id="_7、一个服务端进程最多可以和多少个客户端进行连接-和fd的数量有关吗" tabindex="-1"><a class="header-anchor" href="#_7、一个服务端进程最多可以和多少个客户端进行连接-和fd的数量有关吗" aria-hidden="true">#</a> 7、一个服务端进程最多可以和多少个客户端进行连接？和fd的数量有关吗？</h2><p>答;一个服务端进程可以与多个客户端进行连接，但具体可以支持的最大连接数取决于几个因素，其中包括操作系统和硬件资源的限制、进程所能打开的文件描述符数量，以及应用程序的实现方式。</p><ol><li>操作系统和硬件资源限制：</li></ol><ul><li>操作系统可能对每个进程能够同时处理的网络连接数量设置了限制。这是由操作系统内核的配置参数或者其他资源限制决定的。</li><li>硬件资源如内存、CPU等也会对并发连接数产生影响。</li></ul><ol start="2"><li>文件描述符数量：</li></ol><ul><li>进程所能打开的文件描述符数量限制了其能够管理的连接数量。每个连接对应一个文件描述符，如果文件描述符数量达到上限，则无法建立更多的连接。</li><li>需要注意的是，不仅服务器端需要考虑文件描述符的数量限制，客户端也需要考虑。</li></ul><ol start="3"><li>应用程序实现：</li></ol><ul><li>应用程序的设计和实现方式也影响了能够同时处理的连接数量。例如，采用多线程或多进程模型，可以实现每个线程或进程专门处理一个连接，从而提高并发连接数。</li></ul><p>  综上所述，并发连接数量并非仅与文件描述符数量相关。它还受到操作系统和硬件资源的限制，以及应用程序实现方式的影响。在实际开发中，需要合理的资源规划、优化和管理来满足预期的并发连接需求。</p><h2 id="_8、假设这样一个场景-客户端在和服务端进行tcp的三次握手的过程中-突然间客户端宕机了-那么这个socket怎么处理-可以删除吗-是怎么删除的" tabindex="-1"><a class="header-anchor" href="#_8、假设这样一个场景-客户端在和服务端进行tcp的三次握手的过程中-突然间客户端宕机了-那么这个socket怎么处理-可以删除吗-是怎么删除的" aria-hidden="true">#</a> 8、假设这样一个场景，客户端在和服务端进行TCP的三次握手的过程中，突然间客户端宕机了，那么这个socket怎么处理？可以删除吗？是怎么删除的？</h2>',26),f={href:"https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247520003&idx=1&sn=3e70c6b54007ffa3130c5956df232bdb&chksm=f98dcba9cefa42bfbf35fd5f867314d8c96c54f5b285db542be42fc0594706d1429eaa069165&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},v=p(`<p>  但是，如果「服务端挂掉」指的是「服务端主机宕机」，那么是不会发生四次挥手的，具体后续会发生什么？还要看客户端会不会发送数据？</p><p>  如果客户端会发送数据，由于服务端已经不存在，客户端的数据报文会超时重传，当重传次数达到一定阈值后，会断开 TCP 连接；   如果客户端一直不会发送数据，再看客户端有没有开启 TCP keepalive 机制？ 如果有开启，客户端在一段时间后，检测到服务端的 TCP 连接已经不存在，则会断开自身的 TCP 连接；   如果没有开启，客户端的 TCP 连接会一直存在，并不会断开。</p><p>有关该问题的更详细解答，请查看上述链接。</p><p>  如果挂了的是<strong>客户端</strong>，则：</p><p>  在TCP的三次握手过程中，如果客户端在握手期间宕机或断开连接，服务端会在一定时间内等待客户端的确认消息，这个等待的时间称为超时时间。</p><p>  如果超过超时时间后仍然没有收到来自客户端的确认消息，那么服务端会认为客户端已经宕机或断开连接。此时，服务端会关闭与该客户端的连接，并释放对应的Socket资源。</p><p>  具体的删除过程可以通过以下步骤完成：</p><ol><li>服务端在接收到客户端的连接请求后创建一个Socket对象，并分配一个文件描述符用于标识这个Socket。</li><li>在三次握手过程中，服务端会监听客户端的确认消息。如果超过超时时间后没有收到客户端的确认消息，服务器会发起一系列的重试和超时机制，直至达到最大重试次数或超时时间的上限。</li><li>当超过最大重试次数或超时时间上限后，服务器认为客户端已经宕机或断开连接。</li><li>服务端会关闭与该客户端的连接，释放对应的Socket资源。这包括释放文件描述符、回收关联的内存、关闭相应的网络连接等操作。</li><li>被关闭和释放的Socket会从操作系统的监听队列和相关数据结构中删除，最终被操作系统回收。</li></ol><p>  需要注意的是，即使客户端在握手期间宕机或断开连接，服务端也需要一定的时间来处理这个情况。具体的超时时间和重试次数可以在服务端的TCP配置中进行设置或使用操作系统的默认值。</p><h2 id="_9、在服务端调用accept-之后-socket就是一直可读的吗-就是调用read-函数就一直可以读吗-会阻塞吗" tabindex="-1"><a class="header-anchor" href="#_9、在服务端调用accept-之后-socket就是一直可读的吗-就是调用read-函数就一直可以读吗-会阻塞吗" aria-hidden="true">#</a> 9、在服务端调用<code>accept()</code>之后,socket就是一直可读的吗？就是调用read()函数就一直可以读吗？会阻塞吗？</h2><p>答：在服务端调用<code>accept()</code>之后，返回的socket对象可以被认为是可读的，但并不意味着调用read()函数就一直可以读取数据。</p><p>  调用accept()函数是为了接受客户端的连接请求，并创建一个新的Socket用于与该客户端通信。这个新的Socket对象表示了与客户端的连接。</p><p>  在使用这个连接进行数据传输时，可以使用read()函数从Socket中读取数据，但需要注意以下几点：</p><ol><li>阻塞式读取：</li></ol><ul><li>默认情况下，read()函数是阻塞的，即如果没有数据可读，它会一直阻塞等待直到有数据到达。</li><li>当没有数据到达时，read()函数会阻塞线程的执行，程序无法继续向下执行。只有当有数据到达时，才会从read()函数返回，并返回实际读取到的数据量。</li></ul><ol start="2"><li>非阻塞式读取：</li></ol><ul><li>可以通过设置Socket为非阻塞模式来使用非阻塞式读取。在非阻塞模式下，read()函数会立即返回，无论是否有数据可读。</li><li>在非阻塞模式下，如果没有数据可读，read()函数可能会返回一个特定的错误码（如EWOULDBLOCK或EAGAIN），表示当前没有可读数据。</li></ul><p>  需要注意的是，调用accept()函数只是用于接受客户端连接，并创建一个新的socket对象。之后，服务端需要通过新的socket对象来进行实际的数据传输操作，包括调用read()函数来读取从客户端发送过来的数据。accept()函数和read()函数是不同的功能接口，它们在不同的阶段使用，分别用于建立连接和进行数据传输。</p><h2 id="_10、如果服务端read-函数发生了阻塞-对方客户端异常关闭了-一直没有发数据过来-服务端会一直阻塞吗-会导致服务端卡死吗" tabindex="-1"><a class="header-anchor" href="#_10、如果服务端read-函数发生了阻塞-对方客户端异常关闭了-一直没有发数据过来-服务端会一直阻塞吗-会导致服务端卡死吗" aria-hidden="true">#</a> 10、如果服务端read()函数发生了阻塞,对方客户端异常关闭了,一直没有发数据过来,服务端会一直阻塞吗？会导致服务端卡死吗？</h2><p>答：如果服务端的read()函数发生了阻塞，而对方客户端异常关闭了连接并没有发送数据过来，服务端可能会一直处于阻塞状态，并且有潜在的导致服务端卡死的风险。</p><ul><li>下面是一种可能的情况：</li></ul><ol><li>服务端调用read()函数进行数据读取。</li><li>如果对方客户端异常关闭了连接并没有发送数据，服务端会一直等待数据到达。</li><li>由于对方客户端已经关闭连接，服务端不会收到任何数据，read()函数会一直阻塞等待数据到达。</li><li>如果服务端没有设置合适的超时机制或其他手段来处理阻塞情况，那么服务端可能会一直保持阻塞状态，无法继续向下执行其他操作，从而导致服务端卡死。</li></ol><ul><li>为了避免这种情况，可以采取以下策略：</li></ul><ol><li>设置读取超时机制：使用适当的方式设置read()函数的超时时间，确保当一定时间内没有数据到达时能够及时返回，避免无限阻塞。</li><li>使用非阻塞模式：将服务端的Socket设置为非阻塞模式，这样在没有数据可读时，read()函数会立即返回，并根据返回值进行相应的处理。</li><li>引入心跳机制：使用心跳机制来检测连接是否仍然有效，定期发送心跳包并等待对方的心跳回复。如果一定时间内没有收到心跳回复，可以判断连接已断开。</li></ol><p>  以上措施可以提高服务端的鲁棒性，避免长时间阻塞和卡死的风险。具体实现上述策略的方式与编程语言和网络库有关，可以根据具体情况进行调整。</p><h2 id="_11、在第七题中提到的这个情况-epoll可以解决这个问题吗-如果要识别这个问题-怎么识别" tabindex="-1"><a class="header-anchor" href="#_11、在第七题中提到的这个情况-epoll可以解决这个问题吗-如果要识别这个问题-怎么识别" aria-hidden="true">#</a> 11、在第七题中提到的这个情况，epoll可以解决这个问题吗？如果要识别这个问题，怎么识别？</h2><p>答：Epoll在解决高并发连接问题上具有很好的性能。Epoll是Linux下的一种I/O事件通知机制，它使用了事件驱动的方式，能够高效地处理大量的并发连接。通过使用epoll，可以实现较高的并发性能。</p><p>epoll_create、epoll_ctl和epoll_wait是epoll机制的三个关键函数，它们一起协作实现高并发服务器的功能。</p><ol><li><p>epoll_create函数：创建一个epoll实例，返回一个文件描述符用于标识该实例。该函数会创建一个红黑树（用于存储文件描述符及其对应的事件）和一个就绪链表（用于保存已经就绪的事件）。</p></li><li><p>epoll_ctl函数：用于向epoll实例中添加、修改或删除文件描述符及其对应的事件监听。</p></li></ol><ul><li>添加监听事件：通过指定EPOLL_CTL_ADD操作，在epoll实例中注册要监听的文件描述符和感兴趣的事件类型（如可读、可写等）。</li><li>修改监听事件：通过指定EPOLL_CTL_MOD操作，修改已经注册的文件描述符对应的事件类型。</li><li>删除监听事件：通过指定EPOLL_CTL_DEL操作，从epoll实例中删除不再监听的文件描述符。</li></ul><ol start="3"><li>epoll_wait函数：等待文件描述符上的事件就绪。</li></ol><ul><li>当有文件描述符上的事件就绪时，epoll_wait函数会阻塞，直到有事件发生或达到超时时间。</li><li>当有事件发生或超时时间到达时，epoll_wait函数会将就绪的文件描述符和其对应的事件放入就绪链表中，并返回就绪的文件描述符数量。</li></ul><p>基于上述函数的配合，实现高并发服务器的主要流程如下：</p><ol><li><p>创建一个epoll实例：使用epoll_create函数创建一个epoll实例，并获取返回的文件描述符。</p></li><li><p>添加初始监听事件：使用epoll_ctl函数将要监听的文件描述符和初始感兴趣的事件类型添加到epoll实例中。</p></li><li><p>进入主循环：在一个无限循环中执行以下操作：</p><ul><li><p>a. 调用epoll_wait函数，等待文件描述符上的事件就绪。</p></li><li><p>b. 当有就绪事件时，遍历就绪链表中的事件，根据事件类型执行相应的操作。例如，可读事件可能表示有客户端请求到达，可写事件可能表示可以向客户端发送响应数据。</p></li><li><p>c. 根据具体需求，可能需要重新注册或修改文件描述符的监听事件。</p></li></ul></li><li><p>处理其他业务逻辑：除了处理已就绪的事件外，还可以在主循环中处理其他业务逻辑，如定时任务、心跳检测等。</p></li></ol><p>  通过以上的配合，epoll机制能够高效地处理大量并发连接，避免了传统的轮询方式的效率问题，提升了服务器的并发性能。</p><h2 id="_12、linux进程创建线程的流程是怎么样的" tabindex="-1"><a class="header-anchor" href="#_12、linux进程创建线程的流程是怎么样的" aria-hidden="true">#</a> 12、linux进程创建线程的流程是怎么样的？</h2><p>答：在Linux中，进程创建线程的流程可以通过以下步骤概括：</p><ol><li><p>创建线程：调用pthread_create()函数创建一个新的线程。该函数会将线程标识符（Thread ID）和线程属性作为参数，并指定一个函数作为线程的入口点。</p></li><li><p>初始化线程属性（可选）：如果需要对线程进行特殊处理，可以使用pthread_attr_init()函数初始化线程属性，并通过pthread_attr_set*()函数设置不同的属性，例如线程栈大小、线程优先级等。</p></li><li><p>线程执行：当创建的线程被调度执行时，它将开始执行之前指定的入口点函数。这个函数是由创建线程时传递给pthread_create()的函数。</p></li><li><p>线程执行结束：线程执行完入口点函数后，可以通过return语句返回一个值，也可以调用pthread_exit()函数显式地退出线程。</p></li></ol><p>  总体上，线程的创建流程包括了创建线程、设置线程属性（可选）、线程执行和线程执行结束。可以通过线程库（如pthread库）提供的函数来创建和操作线程。需要注意的是，不同的编程语言和线程库可能会有一些语法和细节上的差异，但基本的流程是相似的。</p><p>  这里以C语言和pthread库为例，演示创建一个简单的线程的流程：</p><div class="language-c++ line-numbers-mode" data-ext="c++"><pre class="language-c++"><code>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;

// 入口点函数
void* threadFunction(void* arg) {
    printf(&quot;This is a thread.\\n&quot;);
    pthread_exit(NULL);
}

int main() {
    pthread_t tid; // 线程标识符

    // 创建线程
    int ret = pthread_create(&amp;tid, NULL, threadFunction, NULL);
    if (ret != 0) {
        fprintf(stderr, &quot;Failed to create thread.\\n&quot;);
        return 1;
    }

    // 等待线程结束
    pthread_join(tid, NULL);

    printf(&quot;Main thread exiting.\\n&quot;);

    return 0;
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>  在上面的示例中，<code>pthread_create()</code>函数用于创建一个新的线程，<code>threadFunction()</code>函数作为线程入口点。在<code>main()</code>函数中，通过<code>pthread_join()</code>函数等待线程执行完毕。最后，主线程打印一条消息后退出。</p><h2 id="_13、线程共享进程的资源在linux中是怎么实现的" tabindex="-1"><a class="header-anchor" href="#_13、线程共享进程的资源在linux中是怎么实现的" aria-hidden="true">#</a> 13、线程共享进程的资源在linux中是怎么实现的？</h2><p>答：在Linux中，线程共享进程的资源是通过以下方式实现的：</p><ol><li><p>共享虚拟地址空间：线程属于同一进程，它们共享进程的虚拟地址空间。这意味着它们可以访1. 问和操作相同的内存区域，无需进行显式的内存拷贝或通信。</p></li><li><p>共享文件描述符：线程可以访问进程打开的文件描述符。当一个线程打开或关闭文件时，对其他线程也会产生影响。这使得多个线程可以方便地对文件进行读写操作，而无需进行额外的同步和通信。</p></li><li><p>共享信号处理：多个线程可以共享进程的信号处理代码。当进程接收到一个信号时，所有线程都可以对该信号进行捕获和处理。这样可以提供更灵活的信号处理机制，使得不同线程有不同的信号处理逻辑。</p></li><li><p>共享全局变量：线程可以直接访问和修改进程的全局变量。对全局变量的读写操作在所有线程之间具有可见性，因此需要进行适当的同步和互斥来保证数据一致性。</p></li><li><p>共享进程属性：线程可以访问和修改进程的属性，例如进程ID、进程组ID等。这些属性对于整个进程来说是共享的，因此对其进行修改会对所有线程产生影响。</p></li></ol><p>  需要注意的是，尽管线程共享进程的资源，在并发情况下仍然需要适当的同步和互斥机制来保护共享资源的一致性。例如，使用互斥锁、条件变量等机制来控制对共享数据的访问。这样可以避免多个线程同时修改共享资源而导致的数据竞争和不一致性。</p><h2 id="_14、线程有自己私有的栈-那么这个栈的内存是被分配到哪里的-是放在进程所属的内存里面-还是说放在独立于进程外部的内存中" tabindex="-1"><a class="header-anchor" href="#_14、线程有自己私有的栈-那么这个栈的内存是被分配到哪里的-是放在进程所属的内存里面-还是说放在独立于进程外部的内存中" aria-hidden="true">#</a> 14、线程有自己私有的栈，那么这个栈的内存是被分配到哪里的？是放在进程所属的内存里面，还是说放在独立于进程外部的内存中？</h2><p>答：线程的私有栈内存是分配在进程所属的内存中的。</p><p>  在大多数操作系统中，每个线程都有自己的栈空间用于存储局部变量、函数调用信息和其他线程私有的数据。这些栈空间通常是在进程创建线程时动态分配的，并且位于进程的虚拟地址空间中。</p><p>具体来说，在Linux系统中，进程的虚拟地址空间包括了以下几个区域：</p><ol><li><p>代码段（Text Segment）：存放程序的可执行代码。</p></li><li><p>数据段（Data Segment）：存放已初始化的全局变量和静态变量。</p></li><li><p>BSS段（Block Started by Symbol）：存放未初始化的全局变量和静态变量的内存。</p></li><li><p>堆（Heap）：由动态分配的内存组成，用于动态申请和释放内存。</p></li><li><p>栈（Stack）：用于存放函数调用的返回地址、局部变量等。</p></li></ol><p>  当创建一个线程时，操作系统会为这个线程分配一块栈空间，通常默认大小为几MB。这个栈空间会被映射到进程的虚拟地址空间的栈段中，位于栈段的底部。每个线程会有自己独立的栈空间，线程之间不会共享栈空间。</p><p>  需要注意的是，栈空间是有限的资源，并且在运行时会自动增长和收缩。当线程调用函数或者发生递归调用时，栈会扩展以容纳更多的局部变量和函数调用信息。而当函数返回或者递归结束时，栈会收缩回原来的大小，释放掉不再需要的空间。</p><p>  因此，线程的私有栈内存是被分配在进程所属的内存中，并且位于进程虚拟地址空间中的栈段。</p><h2 id="_15、什么是协程-协程有什么用" tabindex="-1"><a class="header-anchor" href="#_15、什么是协程-协程有什么用" aria-hidden="true">#</a> 15、什么是协程？协程有什么用？</h2><p>答：协程（Coroutine）是一种用户级的轻量级线程，也被称为“协作式多任务”或“非抢占式多任务”。与操作系统级线程（例如常见的多线程）相比，协程由用户代码主动控制，并且在不同协程之间没有强制切换和抢占的行为。</p><ul><li>协程的特点如下：</li></ul><ol><li><p>主动控制权：协程是由用户代码主动控制的。在一个协程执行时，它会负责运行直到主动让出控制权，然后切换到另一个协程继续执行。</p></li><li><p>非抢占式：与操作系统级线程不同，协程不存在强制的抢占行为。一个协程只有在自己主动让出控制权时，其他协程才能获得执行机会。</p></li><li><p>轻量级：相对于操作系统级线程，协程的资源消耗更小。协程的创建、销毁和切换开销较小，因此可以创建大量的协程而不会导致过多的资源占用。</p></li></ol><ul><li>协程有以下几个常见的用途和好处：</li></ul><ol><li><p>顺序逻辑简化：协程可以在一个函数内部实现多个逻辑片段的切换和执行，避免了复杂的回调机制或多线程间的同步问题。这使得代码更加简洁、易读，尤其适用于处理复杂的异步任务场景。</p></li><li><p>任务调度和协作：协程可以将一个长时间运行的任务分成多个部分执行，使得其他协程有机会执行而不会阻塞整个程序。通过主动让出控制权，协程能够实现高效的任务调度和协作。</p></li><li><p>高并发、高扩展性：由于协程的轻量级特性，可以创建大量的协程来处理并发任务，而不会因为线程或进程创建过多而导致资源耗尽。此外，协程也具备较好的扩展性，可以根据实际需求动态调整协程的数量。</p></li><li><p>状态保存和恢复：协程能够保存当前执行的上下文状态，并在切换回来时恢复状态，这使得协程在编写状态机、迭代器等复杂逻辑时非常方便。</p></li></ol><p>  需要注意的是，协程的具体实现方式和语法会因编程语言和库的不同而有所差异。在一些编程语言中，协程可能是原生支持的（如Go、Python的asyncio），而在其他语言中可能需要依赖第三方库来实现。</p><h2 id="_16、场景题-一致性哈希相关" tabindex="-1"><a class="header-anchor" href="#_16、场景题-一致性哈希相关" aria-hidden="true">#</a> 16、场景题：一致性哈希相关</h2>`,62),x={href:"https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247504513&idx=1&sn=4faa7afcd98b03ef3c24912860317e9e&chksm=f98d962bcefa1f3db85b9f3b3f690359d12089ab93200eb2ce92750ab4224e6d8f145e391402&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},k=p('<h2 id="_17、进程与线程的区别和联系" tabindex="-1"><a class="header-anchor" href="#_17、进程与线程的区别和联系" aria-hidden="true">#</a> 17、进程与线程的区别和联系</h2><p>答：进程和线程是操作系统中的两个重要概念，它们分别代表了程序执行的不同方式。</p><ul><li>区别：</li></ul><ol><li><p>调度单位：进程是操作系统进行资源分配和调度的基本单位，而线程是进程中的一个执行单元。一个进程可以包含多个线程，线程共享进程的资源。进程是资源分配的最先单位，线程是计算机中独立执行、CPU调度的最小单位。</p></li><li><p>资源拥有：每个进程都有独立的地址空间、文件描述符和其他系统资源，而线程则共享进程的这些资源。</p></li><li><p>创建销毁开销：创建或销毁进程比线程更为耗时，因为进程创建时需要分配独立的资源空间，而线程的创建和销毁开销相对较小。</p></li><li><p>通信成本：由于线程共享进程的资源，线程之间的通信成本相对较低，而进程之间的通信成本较高，需要通过进程间通信机制（如管道、消息队列、共享内存等）进行数据传递。</p></li></ol><ul><li>联系：</li></ul><ol><li><p>并发执行：进程和线程都能实现程序的并发执行，提高系统的效率。</p></li><li><p>共享资源：进程和线程都可以访问和共享进程的资源，如内存、文件等。</p></li><li><p>隔离性：进程和线程都具有一定的隔离性，即一个进程或线程的错误不会直接影响其他进程或线程的执行。</p></li><li><p>同步与通信：进程和线程之间可以通过同步机制（如互斥锁、信号量）和通信机制（如管道、消息队列）进行数据交换和同步操作。</p></li></ol><p>  综上所述，进程和线程在调度单位、资源拥有、创建销毁开销、通信成本等方面存在差异。两者都有并发执行、共享资源、隔离性和同步通信等联系。选择使用进程还是线程取决于具体的应用场景和需求。</p><h2 id="_18、进程与线程共享哪些资源-不共享哪些资源" tabindex="-1"><a class="header-anchor" href="#_18、进程与线程共享哪些资源-不共享哪些资源" aria-hidden="true">#</a> 18、进程与线程共享哪些资源？不共享哪些资源？</h2><p>答：线程和进程在资源共享上存在一定的区别。</p><ul><li>共享资源：</li></ul><ol><li><p>内存空间：在同一个进程中的所有线程共享相同的地址空间，即它们可以访问进程的全局变量和堆内存。</p></li><li><p>文件描述符：所有线程都可以访问打开的文件，包括读取和写入文件。</p></li><li><p>共享库和全局变量：多个线程可以同时使用相同的共享库和全局变量。</p></li><li><p>信号处理器：进程中的信号处理器可以由任何线程处理。</p></li></ol><ul><li>不共享资源：</li></ul><ol><li><p>栈空间：每个线程拥有自己的栈空间，用于保存函数调用和局部变量。线程的栈空间是独立的，不共享。</p></li><li><p>寄存器和程序计数器：每个线程都有自己的寄存器集合和程序计数器，用于保存线程的执行状态。</p></li></ol><p>3、 线程特定数据（Thread-specific Data）：线程特定数据是绑定到特定线程的，每个线程都有自己的一份拷贝，不与其他线程共享。</p><ol start="4"><li>文件描述符的属性：线程之间共享文件描述符本身，但它们的属性（如文件偏移量、文件状态标志等）是独立的，不共享。</li></ol><p>  需要注意的是，虽然线程在某些资源上进行共享，但在对共享资源进行操作时，需要使用同步机制（如互斥锁、信号量）来确保线程之间的互斥和协调，以避免数据竞争和不一致性。</p>',16);function g(S,L){const i=o("ExternalLinkIcon");return d(),t("div",null,[s,n(" more "),h,l("p",null,[e("参考链接："),l("a",u,[e("不愧是微信，问的贼细_WebServer"),a(i)])]),_,l("p",null,[e("答：参考"),l("a",m,[e("CSDN"),a(i)]),e(" 线程间的读写情况主要分为以下三类：")]),b,l("p",null,[e("参考小林的微信公众号文章："),l("a",f,[e("字节一面：服务端挂了，客户端的 TCP 连接还在吗？"),a(i)]),e(" 答：如果「服务端挂掉」指的是「服务端进程崩溃」，服务端的进程在发生崩溃的时候，内核会发送 FIN 报文，与客户端进行四次挥手。")]),v,l("p",null,[e("答：参考小林的微信公众号文章："),l("a",x,[e("一致性哈希是什么，使用场景，解决了什么问题？"),a(i)])]),k])}const T=r(c,[["render",g],["__file","2__小林coding的WebServer面试考点_独立版本.html.vue"]]);export{T as default};
